<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Niranjan Krishna realniranjankrishna@gmail.com" />
  <title>Visualizing Linear Regression</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
</head>
<body>
<div id="header">
<h1 class="title"><strong>Visualizing Linear Regression</strong></h1>
<h2 class="author">Niranjan Krishna<br />
realniranjankrishna@gmail.com<br /></h2>
</div>
<h1 id="introduction">Introduction</h1>
<p>This is the first article in a series of articles which have the common goal of visualizing machine learning algorithms. So why visualize a machine learning algorithm?</p>
<ol>
<li><p>It looks cool</p></li>
<li><p>It helps you understand more about what the algorithm does underneath all the high level code.</p></li>
</ol>
<p>We’re gonna be using p5.js in javascript to visualize all the algorithms. Today we are going to be visualizing Linear Regression. Let’s get to it.</p>
<h1 id="setup">Setup</h1>
<p>First, let’s create a p5 js project called LinearRegression.</p>
<div class="sourceCode" bgcolor="black"><pre class="sourceCode python"><code class="sourceCode python"> p5 g <span class="op">-</span>b LinearRegression
 </code></pre></div>
<p>Now our project should be set up with all the libraries included. If you don’t have the p5 project manager install that and come back to this tutorial or manually setup your folder with the necessary libraries.</p>
<h1 id="idea">Idea</h1>
<p>So the basic idea is that the user gets an interactive visualization of Linear Regression. Basically, when a user clicks on a point on the canvas it becomes a data point. And upon clicking a point the p5.js code interactively draws the best fit line to all the points present in the canvas. Pretty cool, right? Let’s get to implementing it.</p>
<h1 id="implementation">Implementation</h1>
<p>First, let’s implement a mouse click function.</p>
<div class="sourceCode" bgcolor="black"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">function</span> <span class="at">mouseClicked</span>() <span class="op">{</span>
  <span class="va">console</span>.<span class="at">log</span>(<span class="st">&quot;Mouse Clicked&quot;</span>)
<span class="op">}</span></code></pre></div>
<p>Now we want to get the coordinates of the mouse click and store that into a data array. Let’s also initialize the weight and bias</p>
<div class="sourceCode" bgcolor="black"><pre class="sourceCode javascript"><code class="sourceCode javascript">
<span class="kw">let</span> data <span class="op">=</span> []<span class="op">;</span>
<span class="kw">let</span> w <span class="op">=</span> <span class="dv">0</span><span class="op">;</span>
<span class="kw">let</span> b <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></code></pre></div>
<p>Now every time the mouse is clicked, we want to store the data into an array and compute the weight and bias for that particular data. Let’s store the mouseCoordinates into the data array.</p>
<div class="sourceCode" bgcolor="black"><pre class="sourceCode javascript"><code class="sourceCode javascript">
<span class="va">data</span>.<span class="at">push</span>([mouseX<span class="op">,</span>mouseY])<span class="op">;</span></code></pre></div>
<p>Let’s figure out how to compute the weight and bias. What we’re trying to do is minimize the error, between out predicted output and the actual output. For that we need to have an error function. We’re going to use Least Squared Regression for this tutorial. <span class="math display">\[E = \sum_{i=1}^{N}(y_{i} - p_{i})^2\]</span> Here <span class="math inline">\(y_{i}\)</span> is the ith y value and <span class="math inline">\(p_{i}\)</span> is the ith predicted value. Since <span class="math inline">\(p_{i} = w\cdot{}x_{i} + b\)</span>, we can also write this as <span class="math display">\[E = \sum_{i=1}^{N}(y_{i} - (w\cdot{}x_{i} + b))^2\]</span> Next, we need to find the value of w and b that will produce the minimum value of this function. We’ve learned from calculus that in order to find the minimum of a function we need to take the partial derivative with respect to the variable, set it to zero and solve for the variable. First let’s expand this expression <span class="math display">\[E = \sum_{i=1}^{N}(y_{i}^2 + (w\cdot{}x_{i} + b)^2 - 2\cdot{}y_{i}\cdot{}(w\cdot{x}+b))\]</span> <span class="math display">\[= \sum_{i=1}^{N}(y_{i}^2 + w^2\cdot{}x_{i}^2 + b^2+2\cdot{}w\cdot{b}\cdot{}x_{i} - 2w\cdot{}y_{i}\cdot{x_{i}}-2b\cdot{}y_{i})\]</span> Separating the sums and rewriting this gives us <span class="math display">\[= \sum_{i=1}^{N}y_{i}^2+w^2\sum_{i=1}^{N}x_{i}^2+\sum_{i=1}^{N}b^2+2wb\sum_{i=1}^{N}x_{i}-2w\sum_{i=1}^{N}x_{i}y_{i}-2b\sum_{i=1}^{N}y_{i}\]</span> <span class="math display">\[= \sum_{i=1}^{N}y_{i}^2+w^2\sum_{i=1}^{N}x_{i}^2+b^2N+2wb\sum_{i=1}^{N}x_{i}-2w\sum_{i=1}^{N}x_{i}y_{i}-2b\sum_{i=1}^{N}y_{i}\]</span> Finding the derivative respect to w gives us <span class="math display">\[\frac{\partial E}{\partial w} = \frac{\partial }{\partial w}\sum_{i=1}^{N}y_{i}^2+\frac{\partial }{\partial w}w^2\sum_{i=1}^{N}x_{i}^2+\frac{\partial }{\partial w}b^2N+\frac{\partial }{\partial w}2wb\sum_{i=1}^{N}x_{i}-\frac{\partial }{\partial w}2w\sum_{i=1}^{N}x_{i}y_{i}-\frac{\partial }{\partial w}2b\sum_{i=1}^{N}y_{i}\]</span> <span class="math display">\[= 0+2w\sum_{i=1}^{N}x_{i}^2+0+2b\sum_{i=1}^{N}x_{i}-2\sum_{i=1}^{N}x_{i}y_{i}+0\]</span> Therefore <span class="math display">\[2w\sum_{i=1}^{N}x_{i}^2+2b\sum_{i=1}^{N}x_{i}-2\sum_{i=1}^{N}x_{i}y_{i} = 0\]</span> <span class="math display">\[w\sum_{i=1}^{N}x_{i}^2+b\sum_{i=1}^{N}x_{i}-\sum_{i=1}^{N}x_{i}y_{i} = 0\]</span> <span class="math display">\[w =\frac{ \sum_{i=1}^{N}x_{i}y_{i} - b\sum_{i=1}^{N}x_{i}}{\sum_{i=1}^{N}x_{i}^2}\]</span> Proceeding in similar fashion for b <span class="math display">\[\frac{\partial E}{\partial b} = \frac{\partial }{\partial b}\sum_{i=1}^{N}y_{i}^2+\frac{\partial }{\partial b}w^2\sum_{i=1}^{N}x_{i}^2+\frac{\partial }{\partial b}b^2N+\frac{\partial }{\partial b}2wb\sum_{i=1}^{N}x_{i}-\frac{\partial }{\partial b}2w\sum_{i=1}^{N}x_{i}y_{i}-\frac{\partial }{\partial b}2b\sum_{i=1}^{N}y_{i}\]</span> <span class="math display">\[= 0+0+2bN+2w\sum_{i=1}^{N}x_{i}+0-2\sum_{i=1}^{N}y_{i}\]</span> Therefore <span class="math display">\[2bN+2w\sum_{i=1}^{N}x_{i}-2\sum_{i=1}^{N}y_{i} = 0\]</span> <span class="math display">\[bN+w\sum_{i=1}^{N}x_{i}-\sum_{i=1}^{N}y_{i} = 0\]</span> <span class="math display">\[b = \frac{\sum_{i=1}^{N}y_{i}-w\sum_{i=1}^{N}x_{i}}{N}\]</span> So we derived the required formulas for w and b. Now it’s time to code them. Let’s iterate over a loop, finding each summation and using them to calculate w and b</p>
<div class="sourceCode" bgcolor="black"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="cf">for</span>(<span class="kw">var</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span>i<span class="op">&lt;</span><span class="va">data</span>.<span class="at">length</span><span class="op">;</span>i<span class="op">++</span>)<span class="op">{</span>
        xsquared<span class="op">+=</span><span class="va">Math</span>.<span class="at">pow</span>(data[i][<span class="dv">0</span>]<span class="op">,</span><span class="dv">2</span>)
        xsum<span class="op">+=</span>data[i][<span class="dv">0</span>]
        xyproduct<span class="op">+=</span>data[i][<span class="dv">0</span>]<span class="op">*</span>data[i][<span class="dv">1</span>]
        ysum<span class="op">+=</span>data[i][<span class="dv">1</span>]
    <span class="op">}</span>
    w <span class="op">=</span> ((xyproduct <span class="op">-</span> b<span class="op">*</span>xsum)/xsquared)
    b <span class="op">=</span> (ysum <span class="op">-</span> w<span class="op">*</span>xsum)/<span class="va">data</span>.<span class="at">length</span></code></pre></div>
<p>Now we have to plot the points and draw the line as it is a visualization project. We are going to use the draw function to draw them.</p>
<div class="sourceCode" bgcolor="black"><pre class="sourceCode python"><code class="sourceCode python">function draw() {
    background(<span class="dv">0</span>)<span class="op">;</span>
    <span class="cf">for</span>(var i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span>i<span class="op">&lt;</span>data.length<span class="op">;</span>i<span class="op">++</span>){
        
        fill(<span class="dv">255</span>)<span class="op">;</span>
        stroke(<span class="dv">255</span>)<span class="op">;</span>
        ellipse(data[i][<span class="dv">0</span>],data[i][<span class="dv">1</span>],<span class="dv">5</span>,<span class="dv">5</span>)<span class="op">;</span>
    }
    ybegin <span class="op">=</span> b<span class="op">;</span>
    yend <span class="op">=</span> w<span class="op">*</span>windowWidth<span class="op">+</span>b<span class="op">;</span>
    strokeWeight(<span class="dv">2</span>)
    line(<span class="dv">0</span>,ybegin,windowWidth,yend)
}</code></pre></div>
<p>Here’s the full code:</p>
<div class="sourceCode" bgcolor="black"><pre class="sourceCode js"><code class="sourceCode javascript"><span class="kw">let</span> data <span class="op">=</span> []<span class="op">;</span>
<span class="kw">let</span> w <span class="op">=</span> <span class="dv">0</span><span class="op">;</span>
<span class="kw">let</span> b <span class="op">=</span> <span class="dv">0</span><span class="op">;</span>
<span class="kw">function</span> <span class="at">setup</span>() <span class="op">{</span>
    <span class="at">createCanvas</span>(windowWidth<span class="op">,</span>windowHeight)<span class="op">;</span>
    
<span class="op">}</span>

<span class="kw">function</span> <span class="at">draw</span>() <span class="op">{</span>
    <span class="at">background</span>(<span class="dv">0</span>)<span class="op">;</span>
    <span class="cf">for</span>(<span class="kw">var</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span>i<span class="op">&lt;</span><span class="va">data</span>.<span class="at">length</span><span class="op">;</span>i<span class="op">++</span>)<span class="op">{</span>
        
        <span class="at">fill</span>(<span class="dv">255</span>)<span class="op">;</span>
        <span class="at">stroke</span>(<span class="dv">255</span>)<span class="op">;</span>
        <span class="at">ellipse</span>(data[i][<span class="dv">0</span>]<span class="op">,</span>data[i][<span class="dv">1</span>]<span class="op">,</span><span class="dv">5</span><span class="op">,</span><span class="dv">5</span>)<span class="op">;</span>
    <span class="op">}</span>
    ybegin <span class="op">=</span> b<span class="op">;</span>
    yend <span class="op">=</span> w<span class="op">*</span>windowWidth<span class="op">+</span>b<span class="op">;</span>
    <span class="at">strokeWeight</span>(<span class="dv">2</span>)
    <span class="at">line</span>(<span class="dv">0</span><span class="op">,</span>ybegin<span class="op">,</span>windowWidth<span class="op">,</span>yend)
<span class="op">}</span>
<span class="kw">function</span> <span class="at">mouseClicked</span>() <span class="op">{</span>
    <span class="va">data</span>.<span class="at">push</span>([mouseX<span class="op">,</span>mouseY])<span class="op">;</span>
    xsquared <span class="op">=</span> <span class="dv">0</span><span class="op">;</span>
    xsum <span class="op">=</span> <span class="dv">0</span><span class="op">;</span>
    xyproduct <span class="op">=</span> <span class="dv">0</span><span class="op">;</span>
    ysum <span class="op">=</span> <span class="dv">0</span><span class="op">;</span>
    <span class="cf">for</span>(<span class="kw">var</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span>i<span class="op">&lt;</span><span class="va">data</span>.<span class="at">length</span><span class="op">;</span>i<span class="op">++</span>)<span class="op">{</span>
        xsquared<span class="op">+=</span><span class="va">Math</span>.<span class="at">pow</span>(data[i][<span class="dv">0</span>]<span class="op">,</span><span class="dv">2</span>)
        xsum<span class="op">+=</span>data[i][<span class="dv">0</span>]
        xyproduct<span class="op">+=</span>data[i][<span class="dv">0</span>]<span class="op">*</span>data[i][<span class="dv">1</span>]
        ysum<span class="op">+=</span>data[i][<span class="dv">1</span>]
    <span class="op">}</span>
    w <span class="op">=</span> ((xyproduct <span class="op">-</span> b<span class="op">*</span>xsum)/xsquared)
    b <span class="op">=</span> (ysum <span class="op">-</span> w<span class="op">*</span>xsum)/<span class="va">data</span>.<span class="at">length</span>
    
<span class="op">}</span>
Here<span class="st">&#39;s the github link : - </span></code></pre></div>
<p>Here’s the Github link : - <a href="https://github.com/The-CS-Student/VisualML/">Link</a></p>
</body>
</html>
